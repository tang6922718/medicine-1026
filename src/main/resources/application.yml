server:
  servlet:
    context-path: /medicine
  port: 8088
logging:
  level:
    com.bonc.medicine: debug
    org.springfromework.web: info
    org.hibernate: error

spring:
  aop:
    auto: true
  datasource:
    #name: test
    url: jdbc:mysql://192.168.1.21:3306/xuanjiuwei?useUnicode=true&characterEncoding=UTF-8&allowMultiQueries=true
    username: root
    password: root123
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.jdbc.Driver
    filters: stat
    maxActive: 20
    initialSize: 1
    maxWait: 60000
    minIdle: 1
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    maxOpenPreparedStatements: 20
  #jackson:
    #设置空如何序列化
    #defaultPropertyInclusion: ALWAYS


  redis:
    host: 192.168.1.20
    password: ~
    port: 6379
    jedis:
      pool:
        max-active: 100
        max-idle: 10
        max-wait: 100000

  data:
    elasticsearch:
      cluster-nodes: 192.168.1.24:9300
      cluster-name: es-cluster
      repositories:
        enabled: true
  kafka:
    bootstrap-servers: hadoop007:9092
    #生产者的配置，大部分我们可以使用默认的，这里列出几个比较重要的属性
    producer:
      #bootstrap-servers: 192.168.1.26:9092
      #每批次发送消息的数量
      batch-size: 16384
      #设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
      retries: 0
      #producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
      buffer-memory: 33554432
      #key序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    #消费者的配置
    consumer:
      #bootstrap-servers: 192.168.1.26:9092

      #Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
      auto-offset-reset: latest
      #是否开启自动提交
      enable-auto-commit: true
      #自动提交的时间间隔
      auto-commit-interval: 100
      #key的解码方式z
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #value的解码方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #在/usr/local/etc/kafka/consumer.properties中有配置
      group-id: test-consumer-group




mybatis:
  mapper-locations: classpath*:mapper/*.xml
  #type-aliases-package: com.bonc.parent.chineseherbalmedicine.entity
  configuration:
    call-setters-on-nulls: true
hbase:
  master: 192.168.1.24
  zookeeper:
    quorum: hadoop003,hadoop004,hadoop005,hadoop006,hadoop007
    property:
      clientPort: 2181
zookeeper:
  znode:
    parent: /hbase

pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  params: count=countSql
  returnPageInfo: check


